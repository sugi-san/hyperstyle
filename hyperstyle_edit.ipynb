{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/hyperstyle/blob/main/hyperstyle_edit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRzve9Y5DucV"
      },
      "outputs": [],
      "source": [
        "#@title セットアップ\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'hyperstyle'\n",
        "\n",
        "# clone repo\n",
        "!git clone https://github.com/cedro3/hyperstyle.git $CODE_DIR\n",
        "\n",
        "# install ninja\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "\n",
        "# Import Packages\n",
        "import time\n",
        "import sys\n",
        "import pprint\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import imageio\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from notebooks.notebook_utils import Downloader, HYPERSTYLE_PATHS, W_ENCODERS_PATHS, run_alignment\n",
        "from utils.common import tensor2im\n",
        "from utils.inference_utils import run_inversion\n",
        "from utils.domain_adaptation_utils import run_domain_adaptation\n",
        "from utils.model_utils import load_model, load_generator\n",
        "from function import *\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "# download pretrained_models\n",
        "! pip install --upgrade gdown\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1NxGZfkE3THgEfPHbUoLPjCKfpWTo08V1', 'pretrained_models.zip', quiet=False)\n",
        "! unzip pretrained_models.zip\n",
        "\n",
        "\n",
        "# set expeiment data\n",
        "EXPERIMENT_DATA_ARGS = {\n",
        "    \"faces\": {\n",
        "        \"model_path\": \"./pretrained_models/hyperstyle_ffhq.pt\",\n",
        "        \"w_encoder_path\": \"./pretrained_models/faces_w_encoder.pt\",\n",
        "        \"image_path\": \"./notebooks/images/face_image.jpg\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    },\n",
        "    \"cars\": {\n",
        "        \"model_path\": \"./pretrained_models/hyperstyle_cars.pt\",\n",
        "        \"w_encoder_path\": \"./pretrained_models/cars_w_encoder.pt\",\n",
        "        \"image_path\": \"./notebooks/images/car_image.jpg\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((192, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    },\n",
        "    \"afhq_wild\": {\n",
        "        \"model_path\": \"./pretrained_models/hyperstyle_afhq_wild.pt\",\n",
        "        \"w_encoder_path\": \"./pretrained_models/afhq_wild_w_encoder.pt\",\n",
        "        \"image_path\": \"./notebooks/images/afhq_wild_image.jpg\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    }\n",
        "}\n",
        "\n",
        "experiment_type = 'faces'\n",
        "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]\n",
        "\n",
        "\n",
        "# Load HyperStyle Model\n",
        "model_path = EXPERIMENT_ARGS['model_path']\n",
        "net, opts = load_model(model_path, update_opts={\"w_encoder_checkpoint_path\": EXPERIMENT_ARGS['w_encoder_path']})\n",
        "print('Model successfully loaded!')\n",
        "\n",
        "\n",
        "# difine function\n",
        "def generate_mp4(out_name, images, kwargs):\n",
        "    writer = imageio.get_writer(out_name + '.mp4', **kwargs)\n",
        "    for image in tqdm(images):\n",
        "        writer.append_data(image)\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def get_latent_and_weight_deltas(inputs, net, opts):\n",
        "    opts.resize_outputs = False\n",
        "    opts.n_iters_per_batch = 5\n",
        "    with torch.no_grad():\n",
        "        _, latent, weights_deltas, _ = run_inversion(inputs.to(\"cuda\").float(), net, opts)\n",
        "    weights_deltas = [w[0] if w is not None else None for w in weights_deltas]\n",
        "    return latent, weights_deltas\n",
        "    \n",
        "\n",
        "def get_result_from_vecs(vectors_a, vectors_b, weights_deltas_a, weights_deltas_b, alpha):\n",
        "    results = []\n",
        "    for i in range(len(vectors_a)):\n",
        "        with torch.no_grad():\n",
        "            cur_vec = vectors_b[i] * alpha + vectors_a[i] * (1 - alpha)\n",
        "            cur_weight_deltas = interpolate_weight_deltas(weights_deltas_a, weights_deltas_b, alpha)\n",
        "            res = net.decoder([cur_vec],\n",
        "                              weights_deltas=cur_weight_deltas,\n",
        "                              randomize_noise=False,\n",
        "                              input_is_latent=True)[0]\n",
        "            results.append(res[0])\n",
        "    return results\n",
        "\n",
        "def interpolate_weight_deltas(weights_deltas_a, weights_deltas_b, alpha):\n",
        "    cur_weight_deltas = []\n",
        "    for weight_idx, w in enumerate(weights_deltas_a):\n",
        "        if w is not None:\n",
        "            delta = weights_deltas_b[weight_idx] * alpha + weights_deltas_a[weight_idx] * (1 - alpha)\n",
        "        else:\n",
        "            delta = None\n",
        "        cur_weight_deltas.append(delta)\n",
        "    return cur_weight_deltas\n",
        "    \n",
        "def show_mp4(filename, width):\n",
        "    mp4 = open(filename + '.mp4', 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video width=\"%d\" controls autoplay loop>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % (width, data_url)))\n",
        "\n",
        "\n",
        "# downloadフォルダ作成\n",
        "import os\n",
        "os.makedirs('download', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9sedWGRg_Dn"
      },
      "outputs": [],
      "source": [
        "#@title サンプル画像表示\n",
        "display_pic('./images/pic2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CFQyaD1Qqe3d"
      },
      "outputs": [],
      "source": [
        "#@title align&反転\n",
        "\n",
        "# --- align処理 ---\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "reset_folder('./images/align')\n",
        "files = sorted(glob.glob('./images/pic2/*.jpg'))\n",
        "for file in tqdm(files):\n",
        "    aligned_image = run_alignment(file)\n",
        "    name = os.path.basename(file)\n",
        "    aligned_image.save('./images/align/'+name)\n",
        "    \n",
        "\n",
        "# --- 反転処理 ---\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "image_paths = sorted(glob.glob('./images/align/*.jpg'))\n",
        "\n",
        "in_images = []\n",
        "all_vecs = []\n",
        "all_weights_deltas = []\n",
        "img_transforms = EXPERIMENT_ARGS['transform']\n",
        "\n",
        "if experiment_type == \"cars\":\n",
        "    resize_amount = (512, 384)\n",
        "else:\n",
        "    resize_amount = (opts.output_size, opts.output_size)\n",
        "\n",
        "for image_path in tqdm(image_paths):\n",
        "    #print(f'Working on {os.path.basename(image_path)}...')\n",
        "    original_image = Image.open(image_path)\n",
        "    original_image = original_image.convert(\"RGB\")\n",
        "    input_image = img_transforms(original_image)\n",
        "    # get the weight deltas for each image\n",
        "    result_vec, weights_deltas = get_latent_and_weight_deltas(input_image.unsqueeze(0), net, opts)\n",
        "    all_vecs.append([result_vec])\n",
        "    all_weights_deltas.append(weights_deltas)\n",
        "    in_images.append(original_image.resize(resize_amount))\n",
        "\n",
        "display_pic('images/align')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKUvlS7w1V1k"
      },
      "outputs": [],
      "source": [
        "#@title 年齢シミュレーション\n",
        "reset_folder('im')\n",
        "from tqdm import tqdm\n",
        "\n",
        "# インデックス指定\n",
        "input = '08.jpg'#@param {type:\"string\"}\n",
        "names = [os.path.basename(x) for x in image_paths]\n",
        "pic_idx = names.index(input)\n",
        "\n",
        "# 編集係数\n",
        "max = 50 #@param {type:\"slider\", min:40, max:70, step:10}\n",
        "min = -50 #@param {type:\"slider\", min:-70, max:-40, step:10}\n",
        "\n",
        "# 編集用ベクトル作成\n",
        "age = torch.load('editing/interfacegan_directions/age.pt').to('cuda')\n",
        "age = torch.reshape(age,(1, 1, 512))\n",
        "pose = torch.load('editing/interfacegan_directions/pose.pt').to('cuda')\n",
        "pose = torch.reshape(pose,(1, 18, 512))\n",
        "w = pose*0.8+age\n",
        "\n",
        "# 画像生成関数\n",
        "def result_img(cur_vec, cur_weight_deltas):\n",
        "  res = net.decoder([cur_vec],\n",
        "                   weights_deltas=cur_weight_deltas,\n",
        "                   randomize_noise=False,\n",
        "                   input_is_latent=True)[0]\n",
        "  output_im = tensor2im(res[0])\n",
        "  return output_im\n",
        "\n",
        "# フレーム作成\n",
        "num = 0\n",
        "for i  in tqdm(range(0, min, -1)):\n",
        "  cur_vec = all_vecs[pic_idx][0]+w*i/10\n",
        "  cur_weight_deltas = all_weights_deltas[pic_idx]\n",
        "  output_im = result_img(cur_vec, cur_weight_deltas)\n",
        "  output_im.save('im/'+str(num).zfill(4)+'.jpg') \n",
        "  num +=1  \n",
        "\n",
        "for j  in tqdm(range(min, max)):\n",
        "  cur_vec = all_vecs[pic_idx][0]+w*j/10\n",
        "  cur_weight_deltas = all_weights_deltas[pic_idx]\n",
        "  output_im = result_img(cur_vec, cur_weight_deltas)\n",
        "  output_im.save('im/'+str(num).zfill(4)+'.jpg') \n",
        "  num +=1\n",
        "\n",
        "for k  in tqdm(range(max, 0, -1)):\n",
        "  cur_vec = all_vecs[pic_idx][0]+w*k/10\n",
        "  cur_weight_deltas = all_weights_deltas[pic_idx]\n",
        "  output_im = result_img(cur_vec, cur_weight_deltas)\n",
        "  output_im.save('im/'+str(num).zfill(4)+'.jpg') \n",
        "  num +=1    \n",
        "\n",
        "# 動画作成&再生\n",
        "! ffmpeg -y -r 15 -i im/%04d.jpg -vcodec libx264 -pix_fmt yuv420p -loglevel error output.mp4\n",
        "show_mp4('output', 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhcPnRCZGtGw"
      },
      "outputs": [],
      "source": [
        "#@title 動画のダウンロード\n",
        "import shutil\n",
        "download_name = 'download/'+os.path.splitext(input)[0]+'.mp4'\n",
        "shutil.copy('output.mp4', download_name)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(download_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "hyperstyle_edit",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}